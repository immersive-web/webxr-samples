<!doctype html>
<!--
Copyright 2018 The Immersive Web Community Group

Permission is hereby granted, free of charge, to any person obtaining a copy of
this software and associated documentation files (the "Software"), to deal in
the Software without restriction, including without limitation the rights to
use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of
the Software, and to permit persons to whom the Software is furnished to do so,
subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS
FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR
COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER
IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
-->
<html>
  <head>
    <meta charset='utf-8'>
    <meta name='viewport' content='width=device-width, initial-scale=1, user-scalable=no'>
    <meta name='mobile-web-app-capable' content='yes'>
    <meta name='apple-mobile-web-app-capable' content='yes'>
    <link rel='icon' type='image/png' sizes='32x32' href='../favicon-32x32.png'>
    <link rel='icon' type='image/png' sizes='96x96' href='../favicon-96x96.png'>
    <link rel='stylesheet' href='../css/common.css'>

    <title>Fixed Foveation in WebXR</title>
  </head>
  <body>
    <header>
      <details open>
        <summary>Barebones WebXR</summary>
        <p>
          This sample shows the areas of the foveated regions and the
          strength of foveation. It also cycles through the foveation
          region.
          white = no foveation
          red = light foveation
          green = medium foveation
          blue = heavy foveation
          purple = maximum foveation
          <a class="back" href="./">Back</a>
        </p>
        <button id="xr-button" disabled>XR not found</button>
      </details>
    </header>
    <main style='text-align: center;'>
      <p>Click 'Enter XR' to see content</p>
    </main>
    <script type="module">
      import {mat4,vec3} from '../js/render/math/gl-matrix.js';
      (function () {
      'use strict';

      // XR globals.
      let xrButton = document.getElementById('xr-button');
      let xrSession = null;
      let xrRefSpace = null;

      // WebGL scene globals.
      let gl = null;

      const NUM_INSTANCES = 1;
      const NUM_ROTATIONS = 16;
      var fragmentShader;
      var program;

      var vertexPositionLocation;
      var vertexColorLocation;
      var vertexTransformLocation;

      var simulation = new Object;
      simulation.CurrentRotation = vec3.create();

      var scene;
      var projMatrix = mat4.create();
      var viewMatrix = mat4.create();
      var eyePosition = vec3.fromValues(1, 1, 1);
      var viewProjMatrix = mat4.create();

      // Checks to see if WebXR is available and, if so, requests an XRDevice
      // that is connected to the system and tests it to ensure it supports the
      // desired session options.
      function initXR() {
        // Is WebXR available on this UA?
        if (navigator.xr) {
          // If the device allows creation of exclusive sessions set it as the
          // target of the 'Enter XR' button.
          navigator.xr.isSessionSupported('immersive-vr').then((supported) => {
            if (supported) {
              // Updates the button to start an XR session when clicked.
              xrButton.addEventListener('click', onButtonClicked);
              xrButton.textContent = 'Enter XR';
              xrButton.disabled = false;
            }
          });
        }
      }

      // Called when the user clicks the button to enter XR. If we don't have a
      // session we'll request one, and if we do have a session we'll end it.
      function onButtonClicked() {
        if (!xrSession) {
          navigator.xr.requestSession('immersive-vr').then(onSessionStarted);
        } else {
          xrSession.end();
        }
      }

      // Called when we've successfully acquired a XRSession. In response we
      // will set up the necessary session state and kick off the frame loop.
      function onSessionStarted(session) {
        xrSession = session;
        xrButton.textContent = 'Exit XR';

        // Listen for the sessions 'end' event so we can respond if the user
        // or UA ends the session for any reason.
        session.addEventListener('end', onSessionEnded);

        // Create a WebGL context to render with, initialized to be compatible
        // with the XRDisplay we're presenting to.
        let canvas = document.createElement('canvas');
        gl = canvas.getContext('webgl2', { xrCompatible: true });

        var vertexShaderSource =
        "#version 300 es\n"+
        "\n"+
        "void main()\n"+
        "{\n"+
        //  xy - coords of the quad, normalized to 0..1
        //  xy  - UV of the source texture coordinate.
        "    const vec2 quad_positions[6] = vec2[6]\n"+
        "    (\n"+
        "        vec2(0.0, 0.0),\n"+
        "        vec2(1.0, 0.0),\n"+
        "        vec2(0.0, 1.0),\n"+

        "        vec2(0.0, 1.0),\n"+
        "        vec2(1.0, 0.0),\n"+
        "        vec2(1.0, 1.0)\n"+
        "    );\n"+
        "\n"+
        "    gl_Position = vec4((quad_positions[gl_VertexID].xy * 2.0) - 1.0, 0.0, 1.0);\n"+
        "}\n";
        var fragmentShaderSource =
          "#version 300 es\n" +
          "out lowp vec4 outColor;\n"+
          "void main()\n"+
          "{\n"+

            "   highp vec2 dx = dFdx(gl_FragCoord.xy), dy = dFdy(gl_FragCoord.xy);\n"+
            "   highp float levelX = floor(0.5*log2(dot(dx, dx)));\n"+
            "   highp float levelY = floor(0.5*log2(dot(dy, dy)));\n" +
            "   lowp vec4 color = vec4(0.0, 0.0, 0.0, 1.0);\n"+
            "   if ((levelX == 0.0) && (levelY == 0.0)) {\n"+
            "       color = vec4(1.0, 1.0, 1.0, 1.0);\n"+               //  1:1 = White
            "   } else if ((levelX == 1.0) && (levelY == 0.0)) {\n"+
            "       color = vec4(1.0, 0.0, 0.0, 1.0);\n"+               //  1:2 = Red
            "   } else if ((levelX == 1.0) && (levelY == 1.0)) {\n"+
            "       color = vec4(0.0, 1.0, 0.0, 1.0);\n"+               //  1:4 = Green
            "   } else if ((levelX == 2.0) && (levelY == 1.0)) {\n"+
            "       color = vec4(0.0, 0.0, 1.0, 1.0);\n"+               //  1:8 = Blue
            "   } else if ((levelX == 2.0) && (levelY == 2.0)) {\n"+
            "       color = vec4(1.0, 0.0, 1.0, 1.0);\n"+               //  1:16 = Purple
            "   }\n"+
            "	outColor = color;\n"+
          "}\n";

        console.log(vertexShaderSource);
        var vertexShader = createShader(gl, gl.VERTEX_SHADER, vertexShaderSource);
        console.log(fragmentShaderSource);
        var fragmentShader = createShader(gl, gl.FRAGMENT_SHADER, fragmentShaderSource);
        program = createProgram(gl, vertexShader, fragmentShader);

        vertexPositionLocation = gl.getAttribLocation(program, "vertexPosition");
        vertexColorLocation = gl.getAttribLocation(program, "vertexColor");
        vertexTransformLocation = gl.getAttribLocation(program, "vertexTransform");

        scene = createScene(gl);

        mat4.perspective(projMatrix, Math.PI / 2, gl.drawingBufferWidth / gl.drawingBufferHeight, 0.1, 10000.0);

        mat4.lookAt(viewMatrix, eyePosition, vec3.fromValues(0, 0, 0), vec3.fromValues(0, 1, 0));

        mat4.multiply(viewProjMatrix, projMatrix, viewMatrix);


        // Use the new WebGL context to create a XRWebGLLayer and set it as the
        // sessions baseLayer. This allows any content rendered to the layer to
        // be displayed on the XRDevice.
        let gllayer = new XRWebGLLayer(session, gl);
        gllayer.fixedFoveation = 1.0;
        session.updateRenderState({ baseLayer: gllayer });

        // Get a reference space, which is required for querying poses. In this
        // case an 'local' reference space means that all poses will be relative
        // to the location where the XRDevice was first detected.
        session.requestReferenceSpace('local').then((refSpace) => {
          xrRefSpace = refSpace;

          // Inform the session that we're ready to begin drawing.
          session.requestAnimationFrame(onXRFrame);
        });
      }

      // Called either when the user has explicitly ended the session by calling
      // session.end() or when the UA has ended the session for any reason.
      // At this point the session object is no longer usable and should be
      // discarded.
      function onSessionEnded(event) {
        xrSession = null;
        xrButton.textContent = 'Enter VR';

        // In this simple case discard the WebGL context too, since we're not
        // rendering anything else to the screen with it.
        gl = null;
      }

      function createShader(gl, type, source) {
        var shader = gl.createShader(type);
        gl.shaderSource(shader, source);
        gl.compileShader(shader);
        var success = gl.getShaderParameter(shader, gl.COMPILE_STATUS);
        if (success) {
          return shader;
        }

        console.log(gl.getShaderInfoLog(shader));
        gl.deleteShader(shader);
      }

      function createProgram(gl, vertexShader, fragmentShader) {
        var program = gl.createProgram();
        gl.attachShader(program, vertexShader);
        gl.attachShader(program, fragmentShader);
        gl.linkProgram(program);
        var success = gl.getProgramParameter(program, gl.LINK_STATUS);
        if (success) {
          return program;
        }

        console.log(gl.getProgramInfoLog(program));
        gl.deleteProgram(program);
      }
      // t - time in milliseconds, integer
      function simulationAdvance(t) {
        var rotation = t / 1000.0;
        simulation.CurrentRotation.x = rotation;
        simulation.CurrentRotation.y = rotation * 0.8;
        simulation.CurrentRotation.z = rotation * 1.2;
      }
      function createCube(gl) {
        var cube = new Object;

        const cubeVertices =
        [
             // positions
             -127, +127, -127, +127 ,  +127, +127, -127, +127 ,  +127, +127, +127, +127 ,  -127, +127, +127, +127 ,	// top
             -127, -127, -127, +127 ,  -127, -127, +127, +127 ,  +127, -127, +127, +127 ,  +127, -127, -127, +127 ,	// bottom

            // colors
             255,   0, 255, 255 ,    0, 255,   0, 255 ,    0,   0, 255, 255 ,  255,   0,   0, 255 ,
               0,   0, 255, 255 ,    0, 255,   0, 255 ,  255,   0, 255, 255 ,  255,   0,   0, 255 ,

        ];

        cube.VertexCount = 8;
        cube.IndexCount = 36;

        var vertexAttribs = new Array(1);
        vertexAttribs[0] = new Object;
        vertexAttribs[0].index = vertexPositionLocation;
        vertexAttribs[0].size = 4;
        vertexAttribs[0].type = gl.BYTE;
        vertexAttribs[0].normalize = true;
        vertexAttribs[0].stride = 0;        // 0 = move forward size * sizeof(type) each iteration to get the next position
        vertexAttribs[0].offset = 0;        // start at the beginning of the buffer

       /* vertexAttribs[1] = new Object;
        vertexAttribs[1].index = vertexColorLocation;
        vertexAttribs[1].size = 4;
        vertexAttribs[1].type = gl.UNSIGNED_BYTE;
        vertexAttribs[1].normalize = true;
        vertexAttribs[1].stride = 0;        // 0 = move forward size * sizeof(type) each iteration to get the next position
        vertexAttribs[1].offset = 8 * 4;    // skip positions part, offset to color, in bytes
         */
        cube.VertexAttribs = vertexAttribs;

        cube.VertexBuffer = gl.createBuffer();
        gl.bindBuffer(gl.ARRAY_BUFFER, cube.VertexBuffer);
        gl.bufferData(gl.ARRAY_BUFFER, new Uint8Array(cubeVertices), gl.STATIC_DRAW);
        console.log("cube.VertexBuffer size " + gl.getBufferParameter(gl.ARRAY_BUFFER, gl.BUFFER_SIZE));
        gl.bindBuffer(gl.ARRAY_BUFFER, null);

        const cubeIndices =
        [
          0, 2, 1, 2, 0, 3,	// top
          4, 6, 5, 6, 4, 7,	// bottom
          2, 6, 7, 7, 1, 2,	// right
          0, 4, 5, 5, 3, 0,	// left
          3, 5, 6, 6, 2, 3,	// front
          0, 1, 7, 7, 4, 0	// back
        ];

        cube.IndexBuffer = gl.createBuffer();
        gl.bindBuffer(gl.ELEMENT_ARRAY_BUFFER, cube.IndexBuffer);
        gl.bufferData(gl.ELEMENT_ARRAY_BUFFER, new Uint16Array(cubeIndices), gl.STATIC_DRAW);
        console.log("cube.IndexBuffer size " + gl.getBufferParameter(gl.ELEMENT_ARRAY_BUFFER, gl.BUFFER_SIZE));
        gl.bindBuffer(gl.ELEMENT_ARRAY_BUFFER, null);

        return cube;
      }

      function GeometryCreateVAO(gl, geometry) {
        geometry.VertexArrayObject = gl.createVertexArray();
        gl.bindVertexArray(geometry.VertexArrayObject);
        gl.bindVertexArray(null);
      }

      function SceneCreateVAOs(gl, scene)
      {
        if (!scene.CreatedVAOs )
        {
          GeometryCreateVAO(gl, scene.Cube);

          // Modify the VAO to use the instance transform attributes.
          gl.bindVertexArray(scene.Cube.VertexArrayObject);
          gl.bindBuffer(gl.ARRAY_BUFFER, scene.InstanceTransformBuffer);
          gl.bindVertexArray(null);

          scene.CreatedVAOs = true;
        }
      }

      function createScene(gl)
      {
        //ovrProgram_Create( &scene->Program, VERTEX_SHADER, FRAGMENT_SHADER, useMultiview );
        var obj = new Object;

        obj.Cube = createCube(gl);
        //var instArr = new Float32Array(NUM_INSTANCES*4*4);
        // Create the instance transform attribute buffer.
        obj.InstanceTransformBuffer = gl.createBuffer();
        gl.bindBuffer(gl.ARRAY_BUFFER, obj.InstanceTransformBuffer);
        gl.bufferData(gl.ARRAY_BUFFER, NUM_INSTANCES * 4 * 4 * 4, gl.DYNAMIC_DRAW);
        console.log("InstanceTransformBuffer size " + gl.getBufferParameter(gl.ARRAY_BUFFER, gl.BUFFER_SIZE));
        gl.bindBuffer(gl.ARRAY_BUFFER, null);

        obj.SceneMatrices = gl.createBuffer();
        gl.bindBuffer(gl.UNIFORM_BUFFER, obj.SceneMatrices);
        gl.bufferData(gl.UNIFORM_BUFFER, 2 * 16 * 4 /*sizeof( ovrMatrix4f )*/ /* 2 view matrices */ + 2 * 16 * 4 /*sizeof( ovrMatrix4f )*/ /* 2 projection matrices */, gl.STATIC_DRAW);
        gl.bindBuffer(gl.UNIFORM_BUFFER, null);

        // Setup random rotations.
        obj.Rotations = new Array(NUM_ROTATIONS);
        for ( var i = 0; i < NUM_ROTATIONS; i++ )
        {
          obj.Rotations[i] = new Object;
          obj.Rotations[i].x = Math.random();
          obj.Rotations[i].y = Math.random();
          obj.Rotations[i].z = Math.random();
        }

        // Setup random cube positions and rotations.
        obj.CubePositions = new Array(NUM_INSTANCES);
        obj.CubeRotations = new Int32Array(NUM_INSTANCES);
        for ( var i = 0; i < NUM_INSTANCES; i++ )
        {
          obj.CubePositions[i] = { x:0, y:0, z:0 };
          // Using volatile keeps the compiler from optimizing away multiple calls to ovrScene_RandomFloat().
          var rx, ry, rz;
          for ( ; ; )
          {
            rx = ( Math.random() - 0.5 ) * ( 50.0 + Math.sqrt( NUM_INSTANCES ) );
            ry = ( Math.random() - 0.5 ) * ( 50.0 + Math.sqrt( NUM_INSTANCES ) );
            rz = ( Math.random() - 0.5 ) * ( 50.0 + Math.sqrt( NUM_INSTANCES ) );
            // If too close to 0,0,0
            if ( Math.abs( rx ) < 4.0 && Math.abs( ry ) < 4.0 && Math.abs( rz ) < 4.0 )
            {
              continue;
            }
            // Test for overlap with any of the existing cubes.
            var overlap = false;
            for ( var j = 0; j < i; j++ )
            {
              if (Math.abs( rx - obj.CubePositions[j].x ) < 4.0 &&
                  Math.abs( ry - obj.CubePositions[j].y ) < 4.0 &&
                  Math.abs( rz - obj.CubePositions[j].z ) < 4.0 )
              {
                overlap = true;
                break;
              }
            }
            if ( !overlap )
            {
              break;
            }
          }

          // Insert into list sorted based on distance.
          var insert = 0;
          const distSqr = rx * rx + ry * ry + rz * rz;
          for ( var j = i; j > 0; j-- )
          {
            var otherPos = obj.CubePositions[j - 1];
            const otherDistSqr = otherPos.x * otherPos.x + otherPos.y * otherPos.y + otherPos.z * otherPos.z;
            if ( distSqr > otherDistSqr )
            {
              insert = j;
              break;
            }
            obj.CubePositions[j] = Object.assign({}, obj.CubePositions[j - 1]);
            obj.CubeRotations[j] = obj.CubeRotations[j - 1];
          }

          obj.CubePositions[insert].x = rx;
          obj.CubePositions[insert].y = ry;
          obj.CubePositions[insert].z = rz;

          obj.CubeRotations[insert] = Math.trunc( Math.random() * ( NUM_ROTATIONS - 0.1 ) );
        }

        obj.CreatedScene = true;

        SceneCreateVAOs(gl, obj);
        return obj;
      }

      function renderFrame(gl, leftVP, leftProjMatrix, leftViewMatrix, rightVP, rightProjMatrix, rightViewMatrix, time, numBuffers) 
      {
        const vps = { 0:leftVP, 1:rightVP };
        gl.clearColor( 0.125, 0.0, 0.125, 1.0);

        // Render the eye images.
        for (var eye = 0; eye < numBuffers; ++eye )
        {
          gl.viewport(vps[eye].x, vps[eye].y, vps[eye].width, vps[eye].height);
          gl.scissor(vps[eye].x, vps[eye].y, vps[eye].width, vps[eye].height);
          gl.disable( gl.SCISSOR_TEST );
          gl.depthMask(false);
          gl.disable( gl.DEPTH_TEST );
          gl.depthFunc( gl.LEQUAL );
          gl.clear( gl.COLOR_BUFFER_BIT | gl.DEPTH_BUFFER_BIT );

          // NOTE: In the non-mv case, latency can be further reduced by updating the sensor prediction
          // for each eye (updates orientation, not position)
          //ovrFramebuffer * frameBuffer = &renderer->FrameBuffer[eye];
          //ovrFramebuffer_SetCurrent( frameBuffer );

          gl.useProgram(program);

          gl.disable( gl.SCISSOR_TEST );
          gl.enable( gl.CULL_FACE );
          gl.cullFace( gl.BACK );
          //gl.viewport( 0, 0, frameBuffer->Width, frameBuffer->Height ) );
          //gl.scissor( 0, 0, frameBuffer->Width, frameBuffer->Height ) );
          gl.bindVertexArray( scene.Cube.VertexArrayObject );

          gl.drawArrays(gl.TRIANGLES, 0, 6)
          gl.bindVertexArray(null);
          gl.useProgram(null);
        }
      }

      let scale = 1;
      let scale_down = true;

      // Called every time the XRSession requests that a new frame be drawn.
      function onXRFrame(time, frame) {
        let session = frame.session;

        // Inform the session that we're ready for the next frame.
        session.requestAnimationFrame(onXRFrame);

        // Get the XRDevice pose relative to the reference space we created
        // earlier.
        let pose = frame.getViewerPose(xrRefSpace);

        // Getting the pose may fail if, for example, tracking is lost. So we
        // have to check to make sure that we got a valid pose before attempting
        // to render with it. If not in this case we'll just leave the
        // framebuffer cleared, so tracking loss means the scene will simply
        // disappear.
        if (pose) {
          let glLayer = session.renderState.baseLayer;

          // If we do have a valid pose, bind the WebGL layer's framebuffer,
          // which is where any content to be displayed on the XRDevice must be
          // rendered.
          gl.bindFramebuffer(gl.FRAMEBUFFER, glLayer.framebuffer);

          gl.clearColor(0.1, 0.2, 0.3, 1.0);

          // Clear the framebuffer
          gl.clear(gl.COLOR_BUFFER_BIT | gl.DEPTH_BUFFER_BIT);

          gl.enable(gl.DEPTH_TEST);
          gl.enable(gl.CULL_FACE);
          gl.useProgram(program);

          // get combined viewport
          let views = [];
          let VP =  { x: 0, y: 0, width:0, height:0 };
          for (let view of pose.views) {
            //view.requestViewportScale(scale);
            glLayer.fixedFoveation = scale;
            let viewport = glLayer.getViewport(view);
            VP.height = viewport.height;
            VP.width += viewport.width; // technically speaking, this works only for side-by-side views, but should be ok for now.
            VP.width /= scale;
            VP.height /= scale;
            views.push(view);
          }

          renderFrame(gl, VP, views[0].projectionMatrix, views[0].viewMatrix, VP, views[0].projectionMatrix, views[0].viewMatrix, time, 1);


          // Normally you'd loop through each of the views reported by the frame
          // and draw them into the corresponding viewport here, but we're
          // keeping this sample slim so we're not bothering to draw any
          // geometry.
          /*for (let view of pose.views) {
            let viewport = glLayer.getViewport(view);
            gl.viewport(viewport.x, viewport.y,
                        viewport.width, viewport.height);

            // Draw a scene using view.projectionMatrix as the projection matrix
            // and view.transform to position the virtual camera. If you need a
            // view matrix, use view.transform.inverse.matrix.
          }*/
          scale += scale_down ? -0.005 : 0.005;
          if (scale >= 1) {
            scale = 1;
            scale_down = true;
          } else if (scale <= 0) {
            scale = 0;
            scale_down = false;
          }
        }
      }

      // Start the XR application.
      initXR();

    })();
    </script>
  </body>
</html>