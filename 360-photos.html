<!doctype html>
<!--
Copyright 2017 The Chromium Authors. All rights reserved.
Use of this source code is governed by a BSD-style license that can be
found in the LICENSE file.
-->
<html>
  <head>
    <meta charset='utf-8'>
    <meta name='viewport' content='width=device-width, initial-scale=1, user-scalable=no'>
    <meta name='mobile-web-app-capable' content='yes'>
    <meta name='apple-mobile-web-app-capable' content='yes'>

    <title>360 Photos</title>

    <link href='css/common.css' rel='stylesheet'></link>

    <script src='js/third-party/gl-matrix-min.js'></script>

    <script src='js/third-party/wglu/wglu-program.js'></script>
    <script src='js/third-party/wglu/wglu-stats.js'></script>
    <script src='js/third-party/wglu/wglu-texture.js'></script>

    <script src='js/webvr-button.js'></script>
    <script src='js/webvr-scene.js'></script>
    <script src='js/webvr-scene-panorama.js'></script>
    <script src='js/webvr-samples-util.js'></script>
    <script src='js/webvr-splash.js'></script>
  </head>
  <body>
    <header>
      <details open>
        <summary>360 Photos</summary>
        <p>
          This sample demonstrates displaying a 360 degree equirectangular stereo
          photo. It intentionally suppresses view position to ensure that the user
          cannot move out of the photo sphere.
        </p>
      </details>
    </header>
    <script>
      (function () {
      'use strict';

      // VR globals.
      let vrButton = null;
      let vrExclusiveFrameOfRef = null;
      let vrNonExclusiveFrameOfRef = null;

      // WebGL scene globals.
      let gl = null;
      let scene = new WebVRScenePanorama({
        url: 'media/textures/chess_pano_4k.jpg',
        topBottomStereo: true
      });

      function initVR() {
        vrButton = new VRDeviceButton({
          onRequestSession: onRequestSession,
          onEndSession: onEndSession
        });
        document.querySelector('header').appendChild(vrButton.domElement);

        if (navigator.vr) {
          navigator.vr.requestDevice().then((device) => {
            vrButton.setDevice(device);

            if (!device)
              return;

            let outputCanvas = document.createElement('canvas');
            let ctx = outputCanvas.getContext('vrpresent');

            device.requestSession({ outputContext: ctx })
                .then((session) => {
                  document.body.appendChild(outputCanvas);
                  onSessionStarted(session);
                });
          });
        }
      }

      function onRequestSession(device) {
        device.requestSession({ exclusive: true }).then((session) => {
          vrButton.setSession(session);
          onSessionStarted(session);
        });
      }

      function onSessionStarted(session) {
        session.addEventListener('end', onSessionEnded);

        if (!gl) {
          gl = VRSamplesUtil.initWebGLContext({
            compatibleVrDevice: session.device
          });

          scene.setWebGLContext(gl);
        }

        session.baseLayer = new VRWebGLLayer(session, gl);

        // When rendering 360 photos/videos you want to ensure that the user's
        // head is always at the center of the rendered media. Otherwise users
        // with 6DoF hardware could walk towards the edges and see a very skewed
        // or outright broken view of the image. To prevent that, we request a
        // 'headModel' frame of reference, which suppresses any positional
        // information from the headset in favor of a head and neck model based
        // solely on the device orientation. (As an added bonus this mode may
        // be more power efficent on some hardware!)
        session.requestFrameOfReference('headModel').then((frameOfRef) => {
          if (session.exclusive) {
            vrExclusiveFrameOfRef = frameOfRef;
          } else {
            vrNonExclusiveFrameOfRef = frameOfRef;
          }
          scene.waitForLoadWithSplashScreen(session, 'media/textures/xr_splash.png').then(() => {
            session.requestFrame(onVRFrame);
          });
        });
      }

      function onEndSession(session) {
        session.end();
      }

      function onSessionEnded(event) {
        if (event.session.exclusive)
          vrButton.setSession(null);
      }

      function onVRFrame(frame) {
        let session = frame.session;
        let frameOfRef = session.exclusive ?
                         vrExclusiveFrameOfRef :
                         vrNonExclusiveFrameOfRef;
        let pose = frame.getDevicePose(frameOfRef);

        scene.startFrame();

        session.requestFrame(onVRFrame);

        gl.bindFramebuffer(gl.FRAMEBUFFER, session.baseLayer.framebuffer);
        gl.clear(gl.COLOR_BUFFER_BIT | gl.DEPTH_BUFFER_BIT);

        if (pose) {
          let views = [];
          for (let view of frame.views) {
            let render_view = new WebVRView();
            render_view.projection_mat = view.projectionMatrix;
            render_view.view_mat = pose.getViewMatrix(view);
            render_view.viewport = view.getViewport(session.baseLayer);

            // It's important to take into account which eye the view is
            // associated with in cases like this, since it informs which half
            // of the stereo image should be used when rendering the view.
            render_view.eye = view.eye
            views.push(render_view);
          }

          scene.drawViewArray(views);
        }

        scene.endFrame();
      }

      // Start the VR application.
      initVR();
      })();
    </script>
  </body>
</html>
