<!doctype html>
<!--
Copyright 2017 The Chromium Authors. All rights reserved.
Use of this source code is governed by a BSD-style license that can be
found in the LICENSE file.
-->
<html>
  <head>
    <meta charset='utf-8'>
    <meta name='viewport' content='width=device-width, initial-scale=1, user-scalable=no'>
    <meta name='mobile-web-app-capable' content='yes'>
    <meta name='apple-mobile-web-app-capable' content='yes'>

    <title>VR Presentation</title>

    <link href='css/common.css' rel='stylesheet'></link>

    <script src='js/third-party/gl-matrix-min.js'></script>

    <script src='js/third-party/wglu/wglu-program.js'></script>
    <script src='js/third-party/wglu/wglu-stats.js'></script>
    <script src='js/third-party/wglu/wglu-texture.js'></script>

    <script src='js/webvr-button.js'></script>
    <script src='js/webvr-scene.js'></script>
    <script src='js/webvr-scene-cube-sea.js'></script>
    <script src='js/webvr-samples-util.js'></script>
  </head>
  <body>
    <header>
      <details open>
        <summary>VR Presentation</summary>
        <p>
          This sample demonstrates how to present a simple WebGL scene to a
          VRDevice. The scene is not rendered to the page prior to VR
          presentation, nor is it mirrored during presentation.
        </p>
      </details>
    </header>
    <main style='text-align: center;'>
      <p>Click 'Enter VR' to see content</p> 
    </main>
    <script>
      (function () {
      'use strict';

      // VR globals.
      let vrButton = null;
      let vrFrameOfRef = null;

      // WebGL scene globals.
      let gl = null;
      let scene = new WebVRSceneCubeSea();

      // Checks to see if WebVR is available and, if so, queries a list of
      // VRDevices that are connected to the system.
      function initVR() {
        // Adds a helper button to the page that indicates if any VRDevices are
        // available and let's the user pick between them if there's multiple.
        vrButton = new VRDeviceButton({
          onRequestSession: onRequestSession,
          onEndSession: onEndSession
        });
        document.querySelector('header').appendChild(vrButton.domElement);

        // Is WebVR available on this UA?
        if (navigator.vr) {
          // Request a list of all the VR Devices connected to the system.
          navigator.vr.getDevices().then((devices) => {
            // Add each device to the 'Enter VR' button.
            for (let device of devices) {
              vrButton.addDevice(device);
            }
          });
        }
      }

      // Called when the user selects a device to present to. In response we
      // will request an exclusive session from that device.
      function onRequestSession(device) {
        device.requestSession({exclusive: true}).then(onSessionStarted);
      }

      // Called when we've successfully acquired a VRSession. In response we
      // will set up the necessary session state and kick off the frame loop.
      function onSessionStarted(session) {
        // This informs the 'Enter VR' button that the session has started and
        // that it should display 'Exit VR' instead.
        vrButton.setSession(session);

        // Listen for the sessions 'end' event so we can respond if the user
        // or UA ends the session for any reason.
        session.addEventListener('end', onSessionEnded);

        // Create a WebGL context to render with, initialized to be compatible
        // with the VRDisplay we're presenting to.
        gl = VRSamplesUtil.initWebGLContext({
          compatibleVrDevice: session.device
        });

        // Initialize the scene's WebGL content
        scene.setWebGLContext(gl);

        // Use the new WebGL context to create a VRWebGLLayer and set it as the
        // sessions baseLayer. This allows any content rendered to the layer to
        // be displayed on the VRDevice.
        session.baseLayer = new VRWebGLLayer(session, gl);

        // Get a frame of reference, which is required for querying poses. In
        // this case an 'eyeLevel' frame of reference means that all poses will
        // be relative to the location where the VRDevice was first detected.
        session.requestFrameOfReference('eyeLevel').then((frameOfRef) => {
          vrFrameOfRef = frameOfRef;

          // Inform the session that we're ready to begin drawing.
          session.requestFrame(onVRFrame);
        });
      }

      // Called when the user clicks the 'Exit VR' button. In response we end
      // the session.
      function onEndSession(session) {
        session.end();
      }

      // Called either when the user has explicitly ended the session (like in
      // onEndSession()) or when the UA has ended the session for any reason.
      // At this point the session object is no longer usable and should be
      // discarded.
      function onSessionEnded(event) {
        vrButton.setSession(null);

        // In this simple case discard the WebGL context too, since we're not
        // rendering anything else to the screen with it.
        gl = null;
      }

      // Called every time the VRSession requests that a new frame be drawn.
      function onVRFrame(frame) {
        let session = frame.session;

        // Per-frame scene setup. Nothing WebVR specific here.
        scene.startFrame();

        // Inform the session that we're ready for the next frame.
        session.requestFrame(onVRFrame);

        // Bind the WebGL layer's framebuffer, which is where any content to be
        // displayed on the VRDevice must be rendered.
        gl.bindFramebuffer(gl.FRAMEBUFFER, session.baseLayer.framebuffer);

        // Clear the framebuffer
        gl.clear(gl.COLOR_BUFFER_BIT | gl.DEPTH_BUFFER_BIT);

        // Get the VRDevice pose relative to the Frame of Reference we created
        // earlier.
        let pose = frame.getDevicePose(vrFrameOfRef);

        // Getting the pose may fail if, for example, tracking is lost. So we
        // have to check to make sure that we got a valid pose before attempting
        // to render with it. If not in this case we'll just leave the
        // framebuffer cleared, so tracking loss means the scene will simply
        // dissapear.
        if (pose) {
          // If we do have a valid pose, loop through each of the views reported
          // by the frame and draw them into the corresponding viewport.
          for (let view of frame.views) {
            let viewport = view.getViewport(session.baseLayer);
            gl.viewport(viewport.x, viewport.y,
                        viewport.width, viewport.height);

            // Draw this view of the scene. What happens in this function really
            // isn't all that important. What is important is that it renders
            // into the VRWebGLLayer's framebuffer, using the viewport into that
            // framebuffer reported by the current view, and using the
            // projection and view matricies from the current view and pose.
            // We bound the framebuffer and viewport up above, and are passing
            // in the appropriate matrices here to be used when rendering.
            scene.draw(view.projectionMatrix, pose.getViewMatrix(view));
          }
        }

        // Per-frame scene teardown. Nothing WebVR specific here.
        scene.endFrame();
      }

      // Start the VR application.
      initVR();
      })();
    </script>
  </body>
</html>
