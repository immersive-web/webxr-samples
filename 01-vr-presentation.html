<!doctype html>
<!--
Copyright 2017 The Chromium Authors. All rights reserved.
Use of this source code is governed by a BSD-style license that can be
found in the LICENSE file.
-->
<html>
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-capable" content="yes">

    <title>01 - VR Presentation</title>

    <link href="css/common.css" rel="stylesheet"></link>

    <script src="js/third-party/gl-matrix-min.js"></script>

    <script src="js/third-party/wglu/wglu-program.js"></script>
    <script src="js/third-party/wglu/wglu-stats.js"></script>
    <script src="js/third-party/wglu/wglu-texture.js"></script>

    <script src="js/webvr-button.js"></script>
    <script src="js/webvr-scene.js"></script>
    <script src="js/webvr-scene-cube-sea.js"></script>
    <script src="js/webvr-samples-util.js"></script>
  </head>
  <body>
    <header>
      <h1>01 - VR Presentation</h1>
      <p>
        This sample demonstrates how to present a simple WebGL scene to a
        VRDevice. The scene is not rendered to the page prior to VR
        presentation, nor is it mirrored during presentation.
      </p>
    </header>
    <script>
      (function () {
      "use strict";

      // VR globals.
      let vrButton = null;
      let vrSession = null;
      let vrFrameOfRef = null;

      // WebGL scene globals.
      let gl = null;
      let scene = new WebVRSceneCubeSea();

      // Checks to see if WebVR is available and, if so, queries a list of
      // VRDevices that are connected to the system.
      function initVR() {
        // Adds a helper button to the page that indicates if any VRDevices are
        // available and let's the user pick between them if there's multiple.
        vrButton = new VRDeviceButton({
          onRequestSession: onRequestSession,
          onEndSession: onEndSession
        });
        document.querySelector('header').appendChild(vrButton.domElement);

        // Is WebVR available on this UA?
        if (navigator.vr) {
          // Request a list of all the VR Devices connected to the system.
          navigator.vr.getDevices().then((devices) => {
            // Add each device to the "Enter VR" button.
            for (let device of devices) {
              vrButton.addDevice(device);
            }
          });
        }
      }

      // Called when the user selects a device to present to. In response we
      // will request an exclusive session from that device.
      function onRequestSession(device) {
        device.requestSession().then(onSessionStarted);
      }

      // Called when we've successfully acquired a VRSession. In response we
      // will set up the necessary session state and kick off the frame loop.
      function onSessionStarted(session) {
        // Hold onto the session object for later use
        vrSession = session;
        vrButton.setSession(session);

        // Listen for the sessions 'ended' event so we can respond if the user
        // or UA ends the session for any reason.
        vrSession.addEventListener('ended', onSessionEnded);

        // Create a WebGL context to render with, initialized to be compatible
        // with the VRDisplay we're presenting to.
        gl = VRSamplesUtil.initWebGLContext({
          compatibleVrDevice: vrSession.device
        });

        // Initialize the scene's WebGL content
        scene.setWebGLContext(gl);

        // Use the new WebGL context to create a VRWebGLLayer and set it as the
        // sessions baseLayer. This allows any content rendered to the layer to
        // be displayed on the VRDevice.
        vrSession.baseLayer = new VRWebGLLayer(vrSession, gl);

        // Get a frame of reference, which is required for querying poses. In
        // this case an "eyeLevel" frame of reference means that all poses will
        // be relative to the location where the VRDevice was first detected.
        vrSession.requestFrameOfReference("eyeLevel").then((frameOfRef) => {
          vrFrameOfRef = frameOfRef;

          // Inform the session that we're ready to begin drawing.
          vrSession.requestFrame(onVRFrame);
        });
      }

      // Called when the user clicks the "Exit VR" button. In response we end
      // the session.
      function onEndSession(session) {
        session.endSession();
      }

      // Called either when the user has explicitly ended the session (like in
      // onEndSession()) or when the UA has ended the session for any reason.
      // At this point the session object is no longer usable and should be
      // discarded.
      function onSessionEnded(event) {
        vrSession = null;
        vrButton.setSession(null);

        // In this simple case discard the WebGL context too, since we're not
        // rendering anything else to the screen with it.
        gl = null;
      }

      // Called every time the VRSession requests that a new frame be drawn.
      function onVRFrame(frame) {
        let session = frame.session;

        // Per-frame scene setup. Nothing WebVR specific here.
        scene.startFrame();

        // Inform the session that we're ready for the next frame.
        session.requestFrame(onVRFrame);

        // Bind the WebGL layer's framebuffer, which is where any content to be
        // displayed on the VRDevice must be rendered.
        gl.bindFramebuffer(gl.FRAMEBUFFER, session.baseLayer.framebuffer);

        // Clear the framebuffer
        gl.clear(gl.COLOR_BUFFER_BIT | gl.DEPTH_BUFFER_BIT);

        // Get the VRDevice pose relative to the Frame of Reference we created
        // earlier.
        let pose = frame.getDevicePose(vrFrameOfRef);

        // Getting the pose may fail if, for example, tracking is lost. So we
        // have to check to make sure that we got a valid pose before attempting
        // to render with it. If not in this case we'll just leave the
        // framebuffer cleared, so tracking loss means the scene will simply
        // dissapear.
        if (pose) {
          // If we do have a valid pose, loop through each of the views reported
          // by the frame and draw them into the corresponding viewport.
          for (let view of frame.views) {
            let viewport = view.getViewport(session.baseLayer);
            gl.viewport(viewport.x, viewport.y,
                        viewport.width, viewport.height);

            // Draw this view of the scene. What happens in this function really
            // isn't all that important. What is important is that it renders
            // into the VRWebGLLayer's framebuffer, using the viewport into that
            // framebuffer reported by the current view, and using the
            // projection and view matricies from the current view and pose.
            // We bound the framebuffer and viewport up above, and are passing
            // in the appropriate matrices here to be used when rendering.
            scene.draw(view.projectionMatrix, pose.getViewMatrix(view));
          }
        }

        // Per-frame scene teardown. Nothing WebVR specific here.
        scene.endFrame();
      }

      // Start the VR application.
      initVR();
      })();
    </script>
  </body>
</html>
